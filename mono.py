import requests
import re
import sys
import urllib3
from bs4 import BeautifulSoup

# SSL uyarÄ±larÄ±nÄ± sustur
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
}

def get_active_domain():
    print("ğŸ” Aktif giriÅŸ adresi taranÄ±yor...")
    for sayi in range(530, 600):
        url = f"https://monotv{sayi}.com"
        try:
            r = requests.get(url, timeout=5, verify=False)
            if r.status_code == 200:
                print(f"âœ… GiriÅŸ adresi bulundu: {url}")
                return url.rstrip('/')
        except:
            continue
    return None

def resolve_base_url(active_domain):
    print("ğŸ“¡ YayÄ±n sunucusu (base_url) tespit ediliyor...")
    # Sitenin kaynak kodundan m3u8 sunucusunu Ã§ekmeye Ã§alÄ±ÅŸÄ±r
    target = f"{active_domain}/channel.html?id=zirve"
    try:
        r = requests.get(target, headers={"Referer": active_domain + "/"}, timeout=10, verify=False)
        match = re.search(r'["\'](https?://[^\s"\']+?)/[\w\-]+/mono\.m3u8', r.text)
        if match:
            res = match.group(1).rstrip('/') + "/"
            print(f"âœ… Otomatik sunucu: {res}")
            return res
    except:
        pass
    
    # Fallback: EÄŸer bulamazsa bilinen en gÃ¼ncel sunucuyu kullan
    fallback = "https://rei.zirvedesin201.cfd/"
    print(f"âš ï¸ Sunucu bulunamadÄ±, yedek kullanÄ±lÄ±yor: {fallback}")
    return fallback

def main():
    active_domain = get_active_domain()
    if not active_domain:
        sys.exit("âŒ MonoTV giriÅŸ adresi bulunamadÄ±.")

    base_url = resolve_base_url(active_domain)
    
    try:
        print("ğŸ“¡ TÃ¼m kanallar taranÄ±yor...")
        resp = requests.get(active_domain, headers=HEADERS, timeout=10, verify=False)
        resp.encoding = 'utf-8'
        soup = BeautifulSoup(resp.text, "html.parser")
        
        m3u_content = ["#EXTM3U"]
        eklenen_kanallar = set() # Ã‡ift kayÄ±t olmasÄ±n diye

        # Sitedeki tÃ¼m <a> etiketlerini tara, iÃ§inde id= olanlarÄ± yakala
        for a in soup.find_all("a", href=re.compile(r'id=([^&]+)')):
            cid = re.search(r'id=([^&]+)', a["href"]).group(1)
            
            if cid in eklenen_kanallar:
                continue
                
            # Kanal adÄ±nÄ± bul (farklÄ± class isimlerini dene)
            name_tag = a.find(class_="channel-name") or a.find(class_="name") or a.find("span")
            status_tag = a.find(class_="channel-status")
            
            if name_tag:
                name = name_tag.get_text(strip=True)
                status = f"[{status_tag.get_text(strip=True)}] " if status_tag else ""
                
                # M3U FormatÄ±na Ekle
                m3u_content.append(f'#EXTINF:-1 group-title="MonoTV Otomatik",{status}{name}')
                m3u_content.append(f'#EXTVLCOPT:http-referrer={active_domain}/')
                m3u_content.append(f'{base_url}{cid}/mono.m3u8')
                
                eklenen_kanallar.add(cid)

        # SonuÃ§larÄ± Kaydet
        if len(m3u_content) > 1:
            with open("mono.m3u", "w", encoding="utf-8") as f:
                f.write("\n".join(m3u_content))
            print(f"ğŸ BAÅARILI: {len(eklenen_kanallar)} kanal mono.m3u dosyasÄ±na yazÄ±ldÄ±.")
        else:
            print("âŒ HiÃ§ kanal bulunamadÄ±.")

    except Exception as e:
        print(f"âŒ Beklenmedik Hata: {e}")

if __name__ == "__main__":
    main()
