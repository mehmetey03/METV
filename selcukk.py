import re
import os
from urllib.request import urlopen, Request
from bs4 import BeautifulSoup

# TÃ¼rkÃ§e karakterleri dÃ¶nÃ¼ÅŸtÃ¼r
def normalize_tvg_id(name):
    replacements = {
        'Ã§': 'c', 'Ã‡': 'C',
        'ÅŸ': 's', 'Å': 'S',
        'Ä±': 'i', 'Ä°': 'I',
        'ÄŸ': 'g', 'Ä': 'G',
        'Ã¼': 'u', 'Ãœ': 'U',
        'Ã¶': 'o', 'Ã–': 'O',
        ' ': '-', ':': '-', '.': '-', '/': '-', ',': '-'
    }
    for old, new in replacements.items():
        name = name.replace(old, new)
    name = re.sub(r'[^a-zA-Z0-9\-]+', '', name)  # Kalan Ã¶zel karakterleri temizle
    return name.lower()

def find_working_selcuksportshd(start=1825, end=1850):
    print("ğŸ§­ Selcuksportshd domainleri taranÄ±yor...")
    headers = {"User-Agent": "Mozilla/5.0"}
    for i in range(start, end+1):
        url = f"https://www.selcuksportshd{i}.xyz/"
        print(f"ğŸ” TaranÄ±yor: {url}")
        try:
            req = Request(url, headers=headers)
            html = urlopen(req, timeout=5).read().decode('utf-8')
            if "uxsyplayer" in html:
                print(f"âœ… Aktif domain bulundu: {url}")
                return html, url
        except:
            continue
    print("âŒ Aktif domain bulunamadÄ±.")
    return None, None

def parse_channel_list_html(html):
    channels = []
    soup = BeautifulSoup(html, "html.parser")
    div = soup.find("div", class_="channel-list")
    if div:
        for a in div.find_all("a", attrs={"data-url": True}):
            name = a.text.strip()
            url = a["data-url"].split("#")[0]  # #poster parametresi kÄ±rpÄ±ldÄ±
            channels.append({"name": name, "url": url})
    return channels

def write_m3u_file(channels, filename="selcukk.m3u", referer=""):
    lines = ["#EXTM3U"]
    for ch in channels:
        tvg_id = normalize_tvg_id(ch['name'])
        lines.append(f'#EXTINF:-1 tvg-id="{tvg_id}" tvg-name="{ch["name"]}" tvg-logo="https://example.com/default-logo.png" group-title="Spor",{ch["name"]}')
        lines.append(f"#EXTVLCOPT:http-referrer={referer}")
        lines.append(ch['url'])
    with open(filename, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
    print(f"âœ… M3U dosyasÄ± oluÅŸturuldu: {filename}")

# -------- Ana iÅŸlem --------
html, referer_url = find_working_selcuksportshd()
channels = []

if html:
    channels = parse_channel_list_html(html)
    if channels:
        write_m3u_file(channels, "selcukk.m3u", referer_url)
    else:
        print("âŒ Kanal listesi bulunamadÄ±.")
else:
    print("â›” HiÃ§bir domain Ã§alÄ±ÅŸmÄ±yor.")
