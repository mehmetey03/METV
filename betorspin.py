import requests
import re
import urllib3
import json

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Adresler
DOMAIN_API = "https://maqrizi.com/domain.php"
TARGET_SITE = "https://63betorspintv.live/"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Referer": TARGET_SITE
}

# GÃœNCELLENMÄ°Å KANAL LÄ°STESÄ°
SABIT_KANALLAR = {
    "beIN Sports 1": "yayinzirve.m3u8", 
    "beIN Sports 2": "yayinb2.m3u8", 
    "beIN Sports 3": "yayinb3.m3u8",
    "beIN Sports 4": "yayinb4.m3u8", 
    "beIN Sports 5": "yayinb5.m3u8", 
    "beIN Sports Haber": "yayinbeinh.m3u8",
    "beIN Sports MAX 1": "yayinbm1.m3u8",
    "beIN Sports MAX 2": "yayinbm2.m3u8",
    "S Sport 1": "yayinss.m3u8", 
    "S Sport 2": "yayinss2.m3u8", 
    "Smart Spor 1": "yayinsmarts.m3u8", 
    "Smart Spor 2": "yayinsms2.m3u8",
    "Tivibu Spor 1": "yayint1.m3u8",
    "Tivibu Spor 2": "yayint2.m3u8", 
    "Tivibu Spor 3": "yayint3.m3u8", 
    "Tivibu Spor 4": "yayint4.m3u8",
    "TRT Spor": "yayintrtspor.m3u8",
    "TRT Spor YÄ±ldÄ±z": "yayintrtspor2.m3u8", 
    "TRT 1": "yayintrt1.m3u8",
    "A Spor": "yayinas.m3u8",
    "ATV": "yayinatv.m3u8",
    "TV 8": "yayintv8.m3u8",
    "TV 8.5": "yayintv85.m3u8",
    "Sky Sports F1": "yayinf1.m3u8",
    "Eurosport 1": "yayineu1.m3u8",
    "Eurosport 2": "yayineu2.m3u8",
    "TABII Spor": "yayinex7.m3u8",
    "TABII Spor 1": "yayinex1.m3u8", 
    "TABII Spor 2": "yayinex2.m3u8", 
    "TABII Spor 3": "yayinex3.m3u8",
    "TABII Spor 4": "yayinex4.m3u8", 
    "TABII Spor 5": "yayinex5.m3u8", 
    "TABII Spor 6": "yayinex6.m3u8",
    "NBA TV": "yayinnba.m3u8",
    "FB TV": "yayinfb.m3u8", 
    "GS TV": "yayingstve.m3u8", 
    "BJK TV": "yayinbjk.m3u8"
}

def find_matches_in_html(html_content):
    """HTML iÃ§inde maÃ§larÄ± bulan basit fonksiyon"""
    matches = []
    
    # TÃ¼m href="channel?id=..." ifadelerini bul
    channel_ids = re.findall(r'href=[\'"]?channel\?id=([^\'" >]+)', html_content)
    
    print(f"ğŸ” Bulunan channel?id= ifadeleri: {len(channel_ids)}")
    
    # Her channel ID iÃ§in maÃ§ bilgilerini bulmaya Ã§alÄ±ÅŸ
    for cid in channel_ids:
        # Bu ID'nin etrafÄ±ndaki HTML'i bul
        pattern = f'href=[\'"]?channel\\?id={re.escape(cid)}[\'"]?[^>]*>([\\s\\S]*?)</a>'
        block_match = re.search(pattern, html_content)
        
        if block_match:
            block_content = block_match.group(1)
            
            # Date bilgisini ara
            date_match = re.search(r'<div[^>]*class=[\'"]date[\'"][^>]*>([^<]+)<', block_content)
            date = date_match.group(1).strip() if date_match else ""
            
            # Event bilgisini ara
            event_match = re.search(r'<div[^>]*class=[\'"]event[\'"][^>]*>([^<]+)<', block_content)
            event = event_match.group(1).strip() if event_match else ""
            
            # Home bilgisini ara
            home_match = re.search(r'<div[^>]*class=[\'"]home[\'"][^>]*>([^<]+)<', block_content)
            home = home_match.group(1).strip() if home_match else ""
            
            # Away bilgisini ara
            away_match = re.search(r'<div[^>]*class=[\'"]away[\'"][^>]*>([^<]+)<', block_content)
            away = away_match.group(1).strip() if away_match else ""
            
            # EÄŸer home ve away varsa (ve kanal deÄŸilse), bu bir maÃ§tÄ±r
            if home and away and home != away and len(home) < 50 and len(away) < 50:
                if "BEIN" not in home.upper() and "TRT" not in home.upper() and "SPOR" not in home.upper():
                    matches.append((cid, date, event, home, away))
    
    return matches

def simple_extract_matches(html_content):
    """Daha basit bir extract yÃ¶ntemi"""
    matches = []
    
    # TÃ¼m <a> tag'larÄ±nÄ± bul
    a_tags = re.findall(r'<a[^>]*>.*?</a>', html_content, re.DOTALL)
    
    print(f"ğŸ” Toplam <a> tag'Ä±: {len(a_tags)}")
    
    for tag in a_tags:
        # channel?id iÃ§erenleri bul
        if 'channel?id=' in tag:
            # ID'yi Ã§Ä±kar
            id_match = re.search(r'channel\?id=([^"\']+)', tag)
            if id_match:
                cid = id_match.group(1)
                
                # Ä°Ã§erikteki text'i al
                # Date
                date_match = re.search(r'class=[\'"]date[\'"][^>]*>([^<]+)<', tag)
                date = date_match.group(1).strip() if date_match else ""
                
                # Event
                event_match = re.search(r'class=[\'"]event[\'"][^>]*>([^<]+)<', tag)
                event = event_match.group(1).strip() if event_match else ""
                
                # Home
                home_match = re.search(r'class=[\'"]home[\'"][^>]*>([^<]+)<', tag)
                home = home_match.group(1).strip() if home_match else ""
                
                # Away
                away_match = re.search(r'class=[\'"]away[\'"][^>]*>([^<]+)<', tag)
                away = away_match.group(1).strip() if away_match else ""
                
                # Teams alternatif (teams class'Ä± iÃ§inde home ve away)
                if not home or not away:
                    teams_match = re.search(r'class=[\'"]teams[\'"][^>]*>.*?class=[\'"]home[\'"][^>]*>([^<]+)<.*?class=[\'"]away[\'"][^>]*>([^<]+)<', tag, re.DOTALL)
                    if teams_match:
                        home = teams_match.group(1).strip()
                        away = teams_match.group(2).strip()
                
                if home and away and home != away:
                    # Kanal deÄŸil, maÃ§ olduÄŸundan emin ol
                    if not any(x in home.upper() for x in ['BEIN', 'TRT', 'SPORT', 'TV', 'KANAL']):
                        matches.append((cid, date, event, home, away))
    
    return matches

def main():
    m3u_list = ["#EXTM3U"]
    
    try:
        # 1. YayÄ±n Sunucusunu Al
        print("ğŸ“¡ Sunucu adresi alÄ±nÄ±yor...")
        domain_response = requests.get(DOMAIN_API, timeout=10)
        print(f"ğŸ“¡ Domain API YanÄ±tÄ±: {domain_response.status_code}")
        
        if domain_response.status_code != 200:
            print("âŒ Domain API'ye eriÅŸilemedi!")
            return
            
        domain_data = domain_response.json()
        base_url = domain_data.get("baseurl")
        
        if not base_url:
            print("âŒ Base URL bulunamadÄ±!")
            return
            
        print(f"ğŸ“¡ Sunucu URL: {base_url}")
        
        # 2. CanlÄ± MaÃ§larÄ± HTML Ä°Ã§inden AyÄ±kla
        print("âš½ CanlÄ± maÃ§ listesi deÅŸifre ediliyor...")
        response = requests.get(TARGET_SITE, headers=HEADERS, timeout=15, verify=False)
        
        if response.status_code != 200:
            print(f"âŒ Siteye eriÅŸilemedi! Status: {response.status_code}")
            return
            
        html_content = response.text
        
        # HTML'yi dosyaya kaydet (debug iÃ§in)
        with open("son_html.html", "w", encoding="utf-8") as f:
            f.write(html_content[:50000])  # Sadece ilk 50k karakter
        print("ğŸ“„ HTML kaydedildi: son_html.html (ilk 50k karakter)")
        
        # HTML'nin ilk 2000 karakterini gÃ¶ster
        print("\nğŸ” HTML'nin ilk 2000 karakteri:")
        print("-" * 50)
        print(html_content[:2000])
        print("-" * 50)
        
        # Ä°lk yÃ¶ntemle maÃ§larÄ± bul
        matches = find_matches_in_html(html_content)
        
        if not matches:
            print("âš ï¸ Ä°lk yÃ¶ntemle maÃ§ bulunamadÄ±, alternatif yÃ¶ntem deneniyor...")
            matches = simple_extract_matches(html_content)
        
        # Benzersiz maÃ§larÄ± al
        unique_matches = []
        seen_ids = set()
        for match in matches:
            cid = match[0]
            if cid not in seen_ids:
                seen_ids.add(cid)
                unique_matches.append(match)
        
        print(f"âœ… Toplam {len(unique_matches)} benzersiz canlÄ± maÃ§ bulundu")
        
        match_count = 0
        for i, (cid, date, event, home, away) in enumerate(unique_matches):
            title = f"{date} | {event} | {home} - {away}"
            
            m3u_list.append(f'#EXTINF:-1 group-title="âš½ CANLI MAÃ‡LAR",{title}')
            m3u_list.append(f"{base_url}{cid}.m3u8")
            match_count += 1
            
            # Ä°lk 5 maÃ§Ä± gÃ¶ster
            if i < 5:
                print(f"   {i+1}. {title} (ID: {cid})")

        # 3. Sabit KanallarÄ± Ekle
        print(f"\nğŸ“º {len(SABIT_KANALLAR)} Sabit spor kanalÄ± ekleniyor...")
        added_channels = set()
        for name, file in SABIT_KANALLAR.items():
            if file and file.strip():
                m3u_list.append(f'#EXTINF:-1 group-title="ğŸ“º SPOR KANALLARI",{name}')
                m3u_list.append(f"{base_url}{file}")
                added_channels.add(name)
        
        print(f"ğŸ“º Eklenen kanallar: {len(added_channels)} adet")

        # 4. Dosyaya Kaydet
        output_file = "betorspin.m3u8"
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("\n".join(m3u_list))
        
        print("-" * 50)
        print(f"âœ… Ä°ÅLEM BAÅARILI!")
        print(f"ğŸ‘‰ {match_count} CanlÄ± MaÃ§ bulundu")
        print(f"ğŸ‘‰ {len(added_channels)} Sabit spor kanalÄ± eklendi")
        print(f"ğŸ“‚ {output_file} dosyasÄ± hazÄ±r")
        print("-" * 50)
        
        # Ek kontrol
        print("\nğŸ” DEBUG BÄ°LGÄ°LERÄ°:")
        print(f"HTML uzunluÄŸu: {len(html_content)} karakter")
        
        # channel?id= ifadelerini say
        channel_count = len(re.findall(r'channel\?id=', html_content))
        print(f"'channel?id=' geÃ§iÅŸ sayÄ±sÄ±: {channel_count}")
        
        # single-match ifadelerini say
        single_match_count = len(re.findall(r'single-match', html_content, re.IGNORECASE))
        print(f"'single-match' geÃ§iÅŸ sayÄ±sÄ±: {single_match_count}")
        
    except Exception as e:
        print(f"âŒ Hata: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
