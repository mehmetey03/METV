import requests
import re
import os
import urllib3
import json
from bs4 import BeautifulSoup

# SSL uyarÄ±larÄ±nÄ± kapat
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# KAYNAK ADRESLERÄ°
# 1. AdÄ±m: Buradan ana sitenin ne olduÄŸunu buluruz
REDIRECT_SOURCE_URL = "http://raw.githack.com/eniyiyayinci/redirect-cdn/main/inattv.html"
# 2. AdÄ±m: BulduÄŸumuz sitenin sonuna bu yolu ekleyip baseurl'i Ã§ekeriz
DOMAIN_API_PATH = "/domain.php"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
}

def get_active_domain():
    """GitHack Ã¼zerinden gÃ¼ncel giriÅŸ adresini esnek bir ÅŸekilde arar."""
    try:
        r = requests.get(REDIRECT_SOURCE_URL, headers=HEADERS, timeout=15, verify=False)
        # Daha esnek bir regex: TÄ±rnak iÃ§indeki http ile baÅŸlayan ilk URL'yi al
        match = re.search(r'(https?://[^\s\'"]+)', r.text)
        if match:
            return match.group(1).rstrip('/')
    except Exception as e:
        print(f"âš ï¸ GitHack'ten domain Ã§ekilemedi: {e}")
    return None

def get_base_url(domain):
    """Bulunan site Ã¼zerinden domain.php'ye gidip baseurl JSON verisini alÄ±r."""
    try:
        api_url = f"{domain}{DOMAIN_API_PATH}"
        r = requests.get(api_url, headers=HEADERS, timeout=10, verify=False)
        data = r.json()
        # JSON iÃ§indeki baseurl'i temizle
        base = data.get("baseurl", "")
        if base:
            return base.replace("\\", "").strip().rstrip('/') + "/"
    except Exception as e:
        print(f"âš ï¸ {domain}{DOMAIN_API_PATH} Ã¼zerinden baseurl alÄ±namadÄ±: {e}")
    return None

def main():
    # 1. ZÄ°NCÄ°R: GitHack -> Aktif Site
    active_domain = get_active_domain()
    if not active_domain:
        print("âŒ HATA: GitHack Ã¼zerinden aktif domain bulunamadÄ±.")
        return

    # 2. ZÄ°NCÄ°R: Aktif Site -> domain.php -> BaseURL
    base_url = get_base_url(active_domain)
    if not base_url:
        print("âŒ HATA: API Ã¼zerinden yayÄ±n sunucusu (baseurl) alÄ±namadÄ±.")
        return
    
    print(f"âœ… Aktif Domain: {active_domain}")
    print(f"ðŸš€ YayÄ±n Sunucusu: {base_url}")

    m3u_content = ["#EXTM3U"]
    
    # 3. ZÄ°NCÄ°R: MaÃ§larÄ± ve KanallarÄ± OluÅŸtur
    try:
        resp = requests.get(active_domain, headers=HEADERS, timeout=15, verify=False)
        soup = BeautifulSoup(resp.text, "html.parser")
        match_items = soup.find_all("div", class_="channel-item")
        
        for item in match_items:
            src = item.get("data-src", "")
            cid_match = re.search(r'id=([^&]+)', src)
            if not cid_match: continue
            cid = cid_match.group(1)

            # Bilgi ayÄ±klama
            teams = item.find_all("span", class_="team-name")
            home = teams[0].get_text(strip=True) if len(teams) > 0 else "Kanal"
            away = teams[1].get_text(strip=True) if len(teams) > 1 else ""
            league = item.find("span", class_="league-text").get_text(strip=True) if item.find("span", class_="league-text") else "CanlÄ±"
            mtime = item.find("span", class_="match-time").get_text(strip=True) if item.find("span", class_="match-time") else ""

            display_name = f"{home} - {away} [{mtime}] ({league})".strip()
            
            m3u_content.append(f'#EXTINF:-1 group-title="CANLI MAÃ‡LAR",{display_name}')
            m3u_content.append(f'#EXTVLCOPT:http-user-agent={HEADERS["User-Agent"]}')
            m3u_content.append(f'#EXTVLCOPT:http-referrer={active_domain}/')
            m3u_content.append(f'{base_url}{cid}/mono.m3u8')
            
    except Exception as e:
        print(f"âš ï¸ MaÃ§ listesi oluÅŸturma hatasÄ±: {e}")

    # Sabit Kanallar (Hepsi dinamik base_url kullanÄ±r)
    fixed_channels = {
        "patron": "beIN Sports 1", "b2": "beIN Sports 2", "b3": "beIN Sports 3",
        "ss1": "S Sport 1", "ss2": "S Sport 2", "t1": "Tivibu Spor 1"
    }

    for cid, name in fixed_channels.items():
        m3u_content.append(f'#EXTINF:-1 group-title="7/24 Kanallar",{name}')
        m3u_content.append(f'#EXTVLCOPT:http-user-agent={HEADERS["User-Agent"]}')
        m3u_content.append(f'#EXTVLCOPT:http-referrer={active_domain}/')
        m3u_content.append(f'{base_url}{cid}/mono.m3u8')

    # Dosyaya Yaz
    if len(m3u_content) > 1:
        with open("karsilasmalar4.m3u", "w", encoding="utf-8") as f:
            f.write("\n".join(m3u_content))
        print(f"ðŸ“‚ karsilasmalar4.m3u gÃ¼ncellendi. ({len(m3u_content)//4} kanal)")

if __name__ == "__main__":
    main()
