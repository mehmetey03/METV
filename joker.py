import requests
import re
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Bu API bazen yavaÅŸ cevap verebilir, timeout'u artÄ±rdÄ±k
DOMAIN_API = "https://maqrizi.com/domain.php"
UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

def get_data():
    base, site, html = "", "", ""
    
    # 1. Base URL Ã‡ekme
    try:
        response = requests.get(DOMAIN_API, timeout=10)
        base = response.json().get("baseurl", "")
        print(f"ğŸ“¡ API'den gelen sunucu: {base}")
    except Exception as e:
        print(f"âš ï¸ API HatasÄ±: {e}")

    # 2. Aktif Siteyi Tarama (AralÄ±ÄŸÄ± 170-199 yaptÄ±k)
    print("ğŸ” Aktif site aranÄ±yor...")
    for i in range(170, 200):
        url = f"https://jokerbettv{i}.com/"
        try:
            # Sitenin gerÃ§ekten ayakta olduÄŸunu kontrol et
            r = requests.get(url, headers={"User-Agent": UA}, timeout=5, verify=False)
            if r.status_code == 200 and "data-stream" in r.text:
                site, html = url, r.text
                print(f"âœ… Aktif Site Bulundu: {url}")
                break
        except:
            continue
    
    return base, site, html

def main():
    base_url, site_url, html_content = get_data()
    
    # EÄŸer site bulunamazsa boÅŸ dosya oluÅŸturma hatasÄ±nÄ± engellemek iÃ§in kontrol
    if not html_content:
        print("âŒ HATA: HiÃ§bir aktif Jokerbet sitesine ulaÅŸÄ±lamadÄ±!")
        return

    m3u = ["#EXTM3U"]
    processed_ids = set()
    processed_urls = set()

    # 1. Ã–nce data-streamx'i kontrol et (tam URL iÃ§eriyor)
    print("ğŸ”„ data-streamx aranÄ±yor...")
    found_streamx = re.findall(r'data-streamx="([^"]+)".*?data-name="([^"]+)"', html_content, re.DOTALL)
    
    for stream_url, name in found_streamx:
        if stream_url not in processed_urls:
            clean_name = name.strip().upper()
            group = "âš½ CANLI MAÃ‡LAR" if "-" in clean_name else "ğŸ“º SABÄ°T KANALLAR"
            
            m3u.append(f'#EXTINF:-1 group-title="{group}",{clean_name}')
            m3u.append(f'#EXTVLCOPT:http-user-agent={UA}')
            m3u.append(f'#EXTVLCOPT:http-referrer={site_url}')
            m3u.append(stream_url)
            processed_urls.add(stream_url)
            print(f"âœ“ data-streamx: {clean_name}")

    # 2. EÄŸer data-streamx bulunamadÄ±ysa, data-stream'i kullan
    if not processed_urls:
        print("ğŸ”„ data-stream aranÄ±yor...")
        found_stream = re.findall(r'data-stream="([^"]+)".*?data-name="([^"]+)"', html_content, re.DOTALL)
        
        for stream_id, name in found_stream:
            if stream_id not in processed_ids:
                clean_name = name.strip().upper()
                group = "âš½ CANLI MAÃ‡LAR" if "-" in clean_name else "ğŸ“º SABÄ°T KANALLAR"
                
                m3u.append(f'#EXTINF:-1 group-title="{group}",{clean_name}')
                m3u.append(f'#EXTVLCOPT:http-user-agent={UA}')
                m3u.append(f'#EXTVLCOPT:http-referrer={site_url}')
                
                # Base URL varsa onu kullan, yoksa direk stream_id'yi kullan
                if base_url:
                    m3u.append(f"{base_url}{stream_id}.m3u8")
                else:
                    m3u.append(f"{stream_id}.m3u8")
                
                processed_ids.add(stream_id)
                print(f"âœ“ data-stream: {clean_name}")

    # 3. HiÃ§biri bulunamazsa alternatif regex dene
    if not processed_urls and not processed_ids:
        print("ğŸ”„ Alternatif pattern aranÄ±yor...")
        # Daha geniÅŸ bir pattern
        alt_pattern = r'data-(?:streamx|stream)="([^"]+)".*?data-name="([^"]+)"'
        found_alt = re.findall(alt_pattern, html_content, re.DOTALL)
        
        for stream_data, name in found_alt:
            clean_name = name.strip().upper()
            group = "âš½ CANLI MAÃ‡LAR" if "-" in clean_name else "ğŸ“º SABÄ°T KANALLAR"
            
            m3u.append(f'#EXTINF:-1 group-title="{group}",{clean_name}')
            m3u.append(f'#EXTVLCOPT:http-user-agent={UA}')
            m3u.append(f'#EXTVLCOPT:http-referrer={site_url}')
            
            # URL mi yoksa ID mi kontrol et
            if stream_data.startswith('http'):
                m3u.append(stream_data)
                print(f"âœ“ Alternatif (URL): {clean_name}")
            elif base_url:
                m3u.append(f"{base_url}{stream_data}.m3u8")
                print(f"âœ“ Alternatif (ID): {clean_name}")
            else:
                m3u.append(f"{stream_data}.m3u8")
                print(f"âœ“ Alternatif (direkt): {clean_name}")

    if len(m3u) > 1:
        with open("joker.m3u8", "w", encoding="utf-8") as f:
            f.write("\n".join(m3u))
        print(f"ğŸš€ BAÅARILI: {len(m3u)//4} yayÄ±n joker.m3u8 dosyasÄ±na kaydedildi.")
    else:
        print("âŒ HATA: Sitede yayÄ±n bulunamadÄ±.")
        print("â„¹ï¸ DEBUG: HTML iÃ§eriÄŸinin bir kÄ±smÄ±:")
        print(html_content[:2000])  # Ä°lk 2000 karakteri gÃ¶ster

if __name__ == "__main__":
    main()
